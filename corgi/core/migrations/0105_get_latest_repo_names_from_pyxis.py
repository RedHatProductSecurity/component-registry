# Generated by Django 3.2.20 on 2023-11-05 23:59

from django.db import migrations
from django.db.models import F, Func, JSONField, Value

from corgi.core.models import Component, SoftwareBuild
from corgi.tasks.pyxis import slow_update_name_for_container_from_pyxis


def get_latest_repo_names_from_pyxis(apps, schema_editor) -> None:
    brew_container_nvrs = (
        Component.objects.filter(type=Component.Type.CONTAINER_IMAGE, arch="noarch")
        # These containers should have pyxis names set since they were processed after we updated
        # the brew collector to check pyxis for names which differ from Brew
        .exclude(meta_attr__has_key="name_from_label_raw")
        # name_checked will not exist if the migration hasn't processed this container yet.
        # name_checked will be True if the migration already processed this container.
        # This value will remain until the migration finishes.
        # This allows the migration to be re-run in case of failure.
        .exclude(meta_attr__has_key="name_checked")
        # select_related() makes filtering on the related model more efficient.
        .select_related("software_build")
        .filter(software_build__build_type=SoftwareBuild.Type.BREW)
        .values_list("nvr", flat=True)
        .iterator()
    )
    # Set the name_checked key in the meta_attr to a JSON "true" value
    meta_attr_func = Func(
        F("meta_attr"),
        Value(["name_checked"]),
        Value(True, JSONField()),
        function="jsonb_set",
    )

    for nvr in brew_container_nvrs:
        # Schedule these tasks at the back of the queue
        # so bulk data loading doesn't block more important daily tasks
        slow_update_name_for_container_from_pyxis.apply_async(args=(nvr,), priority=9)

        # Set this so they are not re-processed next run
        Component.objects.filter(
            type=Component.Type.CONTAINER_IMAGE,
            arch="noarch",
            nvr=nvr,
        ).update(meta_attr=meta_attr_func)

    checked_containers = []
    # Filtering on type + arch first makes below use an index
    # and excludes many unneeded results before doing expensive JSONField filtering
    for container in Component.objects.filter(
        type=Component.Type.CONTAINER_IMAGE, arch="noarch", meta_attr__name_checked=True
    ).iterator():
        del container.meta_attr["name_checked"]
        checked_containers.append(container)
    Component.objects.bulk_update(checked_containers, ["meta_attr"])
    # The built-in Postgres jsonb_set function doesn't allow removing keys from a JSONField
    # This is possible in RawSQL, but I don't want to bother
    # If doing bulk_update() in the migration still causes the pod to run out of memory
    # we know that everything else is finished, and can just remove the name_checked keys ourselves
    # or maybe just leave the values in the meta_attr - they won't hurt anything
    # I will comment out above if so, then finish off migration


class Migration(migrations.Migration):
    atomic = False
    dependencies = [("core", "0104_fix_root_components_condition")]

    operations = [
        migrations.RunPython(get_latest_repo_names_from_pyxis),
    ]
